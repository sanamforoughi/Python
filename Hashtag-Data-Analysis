from tweepy import OAuthHandler
from tweepy import API
from tweepy import Cursor
import json
import pandas as pd
import matplotlib as mpl
#mpl.use('Agg')
import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator
from matplotlib import rcParams
from mpltools import style
from matplotlib import dates
from datetime import datetime
import seaborn as sns
import time
import os
from scipy.misc import imread
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
import random

# Suppressing warnings
import warnings
warnings.filterwarnings("ignore")

# Seaborn plots
sns.set_palette("deep", desat=.6)
sns.set_context(rc={"figure.figsize": (8, 4)})
# for R lovers :)
style.use('ggplot')
rcParams['axes.labelsize'] = 9
rcParams['xtick.labelsize'] = 9
rcParams['ytick.labelsize'] = 9
rcParams['legend.fontsize'] = 7
# rcParams['font.family'] = 'serif'
rcParams['font.serif'] = ['Computer Modern Roman']
rcParams['text.usetex'] = False
rcParams['figure.figsize'] = 20, 10

# Prepapring the app

access_token ="
access_token_secret ="
consumer_key ="
consumer_secret ="

MAX_TWEETS = 8000

# This handles Twitter authentication and the connection to Twitter Streaming API
auth = OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = API(auth, wait_on_rate_limit=True)

# Search 

data = Cursor(api.search, q='bigknit').items(MAX_TWEETS)

# Initialise your list which will contain the returned results as json objects, each list item will be a json format of a tweet with all the information ( and it's a lot)

bigknit_data = []
# You will use this line in production instead of this
# current_working_dir = os.path.dirname(os.path.realpath(__file__))
current_working_dir = "./"
log_tweets = current_working_dir  + str(time.time()) + '_bigknittweets.txt'
with open(log_tweets, 'w') as outfile:
    for tweet in data:
        bigknit_data.append(json.loads(json.dumps(tweet._json)))
        outfile.write(json.dumps(tweet._json))
        outfile.write("\n")

# print bigknit_data[0]

# Dataframes are da bomb 
tweets = pd.DataFrame()

# We want to know when a tweet was sent
tweets['created_at'] = map(lambda tweet: time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(tweet['created_at'],'%a %b %d %H:%M:%S +0000 %Y')), bigknit_data)

# Who is the tweet owner
tweets['user'] = map(lambda tweet: tweet['user']['screen_name'], bigknit_data)

# How many follower this user has
tweets['user_followers_count'] = map(lambda tweet: tweet['user']['followers_count'], bigknit_data)

# What is the tweet's content
tweets['text'] = map(lambda tweet: tweet['text'].encode('utf-8'), bigknit_data)

# If available what is the language the tweet is written in
tweets['lang'] = map(lambda tweet: tweet['lang'], bigknit_data)

# If available, where was the tweet sent from ?
tweets['Location'] = map(lambda tweet: tweet['place']['country'] if tweet['place'] != None else None, bigknit_data)

# How many times this tweet was retweeted and favorited
tweets['retweet_count'] = map(lambda tweet: tweet['retweet_count'], bigknit_data)
tweets['favorite_count'] = map(lambda tweet: tweet['favorite_count'], bigknit_data)

print tweets.head()
